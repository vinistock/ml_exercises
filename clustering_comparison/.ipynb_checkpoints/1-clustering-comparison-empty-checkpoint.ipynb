{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado Não Supervisionado - Agrupamento de Dados\n",
    "#### Prof. Thomas da Silva Paula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação de algoritmos de Agrupamento de Dados\n",
    "\n",
    "É muito comum realizarmos comparação de algoritmos durante o desenvolvimento de soluções que utilizam Machine Learning. No caso de Aprendizado Supervisionado, existem muitas formas de avaliar os resultados, tais como Matriz de Confusão, Medida F1 e Curva ROC. No entanto, a avaliação de algoritmos de Aprendizado Não Supervisionado tem desafios adicionais, pois não temos algo sendo otimizado diretamente. Isso torna a avaliação mais complexa e um tanto quanto subjetiva, principalmente no caso de Agrupamento de Dados. Neste trabalho, iremos exercitar esses conceitos, realizando tarefas muito similares às que Cientistas de Dados fazem no seu dia-a-dia. \n",
    "\n",
    "\n",
    "### Descrição\n",
    "\n",
    "#### Algoritmos\n",
    "Implementar três algoritmos diferentes de agrupamento de dados (utilizando as bibliotecas `scikit-learn` e `scipy`), para realizar agrupamento de diferentes imagens de uma base de dados. Idealmente os algoritmos devem ser de tipos diferents. Para facilitar o processo de feature extraction, foram disponibilizados dois Numpy arrays com as features das imagens extraídas com uma VGG16 e uma ResNet18. Tais features devem ser utilizadas como entrada para os diferentes algoritmos de agrupamento de dados escolhidos.\n",
    "\n",
    "\n",
    "#### Avaliação (Validação) dos Clusters\n",
    "* **Quantitativa**:Para comparação dos algoritmos, devem ser escolhidos três métodos de avaliação diferentes, sendo um interno, um externo e um relativo. O objetivo é avaliar a diferença dos índices para diferentes hiperparâmetros de um mesmo algoritmo e para comparar os resultados de diferentes algoritmos. Lembre-se das diferenças de cada um deles e quando eles se aplicam.\n",
    "* **Subjetiva:** Para a avaliação subjetiva, deve-se criar uma visualização das imagens dos grupos (pode-se inspirar no exemplo mostrado pelo professor).\n",
    "\n",
    "\n",
    "### Requisitos\n",
    "* Escolher três algoritmos diferentes de agrupamento de dados. Escolher um de cada paradigma diferente, como por exemplo um particional, um hierárquico e um por densidade. Podem ser algoritmos não vistos em aula, como Mean-Shift, Spectral Clustering, Affinity Propagation, entre outros.\n",
    "* Escolher e implementar os três algoritmos usando as bibliotecas `scikit-learn` e `scipy`.\n",
    "* Escolher e implementar os três métodos de avaliação, lembrando que deve-se utilizar um índice interno, um externo e um relativo. Usar os índices onde foram aplicáveis e, caso acredite que não se aplique, justifique suas escolhas.\n",
    "* Realizar experimentos com dois conjuntos diferentes de features, sendo um deles da VGG16 e outra da ResNet18.\n",
    "* Implementar um método para comparação subjetiva (visual), onde deve ser possível visualizar imagens de diferentes grupos.\n",
    "* A partir dos experimentos realizados, deve-se escrever um relatório detalhando as escolhas feitas, os experimentos realizados e, principalmente, o aprendizado. Os diferentes hiperparâmetros utilizados (e.g. $\\epsilon$ do DBSCAN) em diferentes experimentos não precisam ser todos colocados, porém o racional para ter chegado em tais valores deve ficar claro (o que implica em explicar por onde começou). É importante colocar os desafios e dificuldades enfrentadas.\n",
    "* Você pode utilizar diferentes estratégias de pré-processamento e redução de dimensionalidde. Fica a seu critério.\n",
    "* **Atenção!**: Existe um número \"correto\" de grupos para essa base de dados, porém a análise não deve se concentrar apenas neste número. Use a criatividade e explore diferentes formas em que os dados podem ser agrupados, fugindo do que seriam os agrupamentos mais \"naturais\"!\n",
    "\n",
    "\n",
    "#### Ideias extras\n",
    "* **(Extra 1)**: Foram disponibilizadas features da ResNet101 também. Um bom exercício é utilizar os algoritmos com os melhores hiperparâmetros com as features da ResNet101 e comparar com os resultados da VGG16 e da ResNet18.\n",
    "* **(Extra 2)**: Vamos aprender nas próximas aulas sobre redução de dimensionalidade. Faça experimentos com redução de dimensionalidade e compare com os agrupamentos anteriores. Faça a redução para duas dimensões e observe se a separação dos dados.\n",
    "\n",
    "### Exemplo de visualização subjetiva\n",
    "![alt text](cluster_evaluation.png \"Exemplo Visualização\")\n",
    "\n",
    "#### Entrega final\n",
    "* Jupyter notebook com os experimentos realizados (.ipynb e um .html ou .pdf).\n",
    "* Relatório em formato .pdf com os resultados e conclusões. Caso prefira, os resultados e conclusões podem ser colocados diretamente no Jupyter notebook, desde que fique bem explicado e claro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Class definition\n",
    "#\n",
    "# For simplicity and re-usability, the solution is written\n",
    "# in a class. Steps are invoked and documented below.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "\n",
    "class Net:\n",
    "    # __init__\n",
    "    #\n",
    "    # Initialize object and load\n",
    "    # features and labels\n",
    "    def __init__(self):\n",
    "        self.labels = None\n",
    "        self.vgg_features = None\n",
    "        self.resnet_features = None\n",
    "        self.kmeans_model = None\n",
    "        self.labels_kmeans = None\n",
    "        self.__load_features__()\n",
    "        \n",
    "    # __load_features__\n",
    "    #\n",
    "    # Load features and labels from the \n",
    "    # compressed npy files\n",
    "    def __load_features__(self):\n",
    "        self.labels = np.load(\"./features/original_labels.npy\")\n",
    "        self.vgg_features = np.load(\"./features/vgg16_features.npy\")\n",
    "        self.resnet_features = np.load(\"./features/resnet18_features.npy\")\n",
    "    \n",
    "    # fit_kmeans\n",
    "    #\n",
    "    # Fits and predicts clusters using kmeans\n",
    "    def fit_kmeans(self):\n",
    "        self.kmeans_model = cluster.KMeans()\n",
    "        self.labels_kmeans = self.kmeans_model.fit_predict(self.vgg_features)\n",
    "    \n",
    "    # display\n",
    "    #\n",
    "    # General purpose debug method\n",
    "    def display(self):\n",
    "        print(self.labels)\n",
    "        print(self.labels_kmeans)\n",
    "\n",
    "# Instantiate object loading all features\n",
    "# and labels\n",
    "net = Net()\n",
    "\n",
    "net.fit_kmeans()\n",
    "net.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
